{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd451a5b-2d27-4797-ac93-8c60c7f1c0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os \n",
    "from glob import glob\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import nrrd\n",
    "from einops import rearrange, reduce, repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb704eb-c740-4861-b25f-a54f4c97e3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbb6f36-f95b-4425-8041-7036195be967",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "\n",
    "# 내가 사용할 GPU번호(0,1,2,3)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus: \n",
    "    try: # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus: \n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "             \n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU') \n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\") \n",
    "    \n",
    "    except RuntimeError as e: # Memory growth must be set before GPUs have been initialized \n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7018b8-92e8-4704-a370-6cd1402fcee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptid = sorted(os.listdir('./data/original1125/'))\n",
    "df_ptid = pd.DataFrame(ptid, columns=['ptid'])\n",
    "all_inputpath = list('./data/original1125/'+df_ptid['ptid']+'/img/')\n",
    "all_label = './data/original1125/'+df_ptid['ptid']\n",
    "all_labelpath = []\n",
    "for i in range(len(all_label)):\n",
    "    all_labelpath.append(glob(all_label[i]+'/*.nrrd')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1cbfb8-3ba0-4d2e-a2d9-6ba527d94cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_files = all_inputpath[:31]\n",
    "train_label_files = all_labelpath[:31]\n",
    "\n",
    "val_input_files = all_inputpath[31:38]\n",
    "val_label_files = all_labelpath[31:38]\n",
    "\n",
    "test_input_files = all_inputpath[38:]\n",
    "test_label_files = all_labelpath[38:]\n",
    "\n",
    "print(len(train_input_files), len(val_input_files), len(test_input_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42a018e-2073-4478-a4a7-c8c9c0e1e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "img_size = 128\n",
    "weights = None\n",
    "# weights = 'imagenet'\n",
    "learning_rate = 1e-4\n",
    "EPOCHS = 400\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0f2f89-4fce-4b85-a957-ccc625064d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inp_files = glob(f'./data{img_size}/train_input_img_{img_size}/*.npy')\n",
    "train_targ_files = glob(f'./data{img_size}/train_label_img_{img_size}/*.npy')\n",
    "\n",
    "val_inp_files = glob(f'./data{img_size}/val_input_img_{img_size}/*.npy')\n",
    "val_targ_files = glob(f'./data{img_size}/val_label_img_{img_size}/*.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d61f37-b340-4b26-aa7a-1aa8960197ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inp_files = glob(f'./data{img_size}/train_input_img_{img_size}/*.npy')\n",
    "train_targ_files = glob(f'./data{img_size}/train_label_img_{img_size}/*.npy')\n",
    "\n",
    "val_inp_files = glob(f'./data{img_size}/val_input_img_{img_size}/*.npy')\n",
    "val_targ_files = glob(f'./data{img_size}/val_label_img_{img_size}/*.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03f1c78-0bb3-4f2d-b8ce-378f0c004669",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inp_files, train_targ_files = shuffle(train_inp_files, train_targ_files, random_state=42)\n",
    "len(train_inp_files), len(val_inp_files), len(train_targ_files), len(val_targ_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46760f9d-9ba1-44cb-b229-5ba138d25fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_map_func(inp_path, targ_path):\n",
    "    inp = np.load(inp_path)\n",
    "    inp = inp.astype(np.float32)\n",
    "    targ = np.load(targ_path)\n",
    "    targ = targ.astype(np.float32)\n",
    "    inp, targ = augmentation(inp, targ)\n",
    "    \n",
    "    return inp, targ\n",
    "\n",
    "def val_map_func(inp_path, targ_path):\n",
    "    inp = np.load(inp_path)\n",
    "    inp = inp.astype(np.float32)\n",
    "    targ = np.load(targ_path)\n",
    "    targ = targ.astype(np.float32)\n",
    "    return inp, targ\n",
    "\n",
    "def augmentation(inp, targ):\n",
    "    inp, targ = random_rot(inp, targ)\n",
    "    inp, targ = random_flip(inp, targ)\n",
    "    \n",
    "    return inp, targ\n",
    "\n",
    "def random_rot(inp, targ):\n",
    "    k = np.random.randint(4)\n",
    "    inp = np.rot90(inp, k)\n",
    "    targ = np.rot90(targ, k)\n",
    "    \n",
    "    return inp, targ\n",
    "\n",
    "def random_flip(inp, targ):\n",
    "    f = np.random.randint(2)\n",
    "    if f == 0:\n",
    "        inp = np.fliplr(inp)\n",
    "        targ = np.fliplr(targ)\n",
    "        \n",
    "    return inp, targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbcf98e-ef31-4474-9c32-290d3ba45f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_inp_files, train_targ_files))\n",
    "train_dataset = train_dataset.map(lambda item1, item2: tf.numpy_function(train_map_func, [item1, item2], [tf.float32, tf.float32]), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_inp_files, val_targ_files))\n",
    "val_dataset = val_dataset.map(lambda item1, item2: tf.numpy_function(val_map_func, [item1, item2], [tf.float32, tf.float32]), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a5cb7c-0716-4361-b747-cb239442f70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "class Dataloader(Sequence):\n",
    "\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "\n",
    "\t\t# batch 단위로 직접 묶어줘야 함\n",
    "    def __getitem__(self, idx):\n",
    "\t\t\t\t# sampler의 역할(index를 batch_size만큼 sampling해줌)\n",
    "        # indices = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        # batch_x = [self.x[i] for i in indices]\n",
    "        # batch_y = [self.y[i] for i in indices]\n",
    "\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "\n",
    "\n",
    "train_loader = Dataloader(X_train, y_train, 128)\n",
    "valid_loader = Dataloader(X_valid, y_valid, 128)\n",
    "# test_loader = Dataloader(x, y, 128)\n",
    "\n",
    "history = model.fit(train_loader, epochs=300, \n",
    "                    validation_data=valid_loader,\n",
    "                    callbacks=[cb]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ccb134-3aa0-487e-a08c-6941d129ebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('models/3dunet_dice_128.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d87edd-74d7-4d38-bb23-c24fd5f2c488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img_paths, stride=128): #batch_size\n",
    "    results = []\n",
    "    for img_path in img_paths:\n",
    "        l = len(os.listdir(img_path))\n",
    "        batch_size = int(np.ceil(l//stride))\n",
    "        rawimg = np.zeros((512,512,l))\n",
    "        for i in range(l):\n",
    "            slice = pydicom.read_file(img_path+'IMG'+str(i+1))\n",
    "            s = int(slice.RescaleSlope)\n",
    "            b = int(slice.RescaleIntercept)\n",
    "            image = s * slice.pixel_array + b\n",
    "            rawimg[:,:,i]=image\n",
    "        rawimg = np.expand_dims(rawimg,axis=3)\n",
    "        clipimg = np.clip(rawimg, -1450,50)\n",
    "        img = (clipimg-np.min(clipimg))/(np.max(clipimg)-np.min(clipimg))\n",
    "        img = img.astype(np.float32)\n",
    "        crop = []\n",
    "        position = []\n",
    "        batch_count = 0\n",
    "\n",
    "        result_img = np.zeros_like(img)\n",
    "        # print(result_img.shape)\n",
    "        voting_mask = np.zeros_like(img)\n",
    "\n",
    "        for top in tqdm(range(0, img.shape[0], stride)):\n",
    "            for left in range(0, img.shape[1], stride):\n",
    "                for slicer in range(0, img.shape[2], stride):\n",
    "                    piece = np.zeros([img_size, img_size, img_size,1], np.float32)\n",
    "                    temp = img[top:top+img_size, left:left+img_size, slicer:slicer+img_size, :]\n",
    "                    piece[:temp.shape[0], :temp.shape[1], :temp.shape[2], :] = temp\n",
    "                    crop.append(piece)\n",
    "                    position.append([top, left, slicer])\n",
    "                    batch_count += 1\n",
    "                    if batch_count == batch_size:\n",
    "                        crop = np.array(crop)\n",
    "                        pred = model(crop)\n",
    "                        crop = []\n",
    "                        batch_count = 0\n",
    "                        for num, (t, l, sl) in enumerate(position):\n",
    "                            piece = pred[num]\n",
    "                            h, w, s, c= result_img[t:t+img_size, l:l+img_size, sl:sl+img_size, :].shape\n",
    "                            result_img[t:t+img_size, l:l+img_size, sl:sl+img_size, :] += piece[:h, :w, :s, :c]\n",
    "                            voting_mask[t:t+img_size, l:l+img_size, sl:sl+img_size, :] += 1\n",
    "                        position = []\n",
    "        \n",
    "        result_img = result_img/voting_mask\n",
    "        result_img = result_img.astype(np.float32)\n",
    "        results.append(result_img)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0ed54b-ddd0-4ed9-9b82-8d9e2b018883",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predict(val_input_files[:2], stride=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99ca18c-0c84-48d1-afe1-74102fb009cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(result[0]).shape)\n",
    "\n",
    "print(np.array(result[1]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb47dede-6e0f-40f4-b303-0db88ae810ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = np.array(result[1])\n",
    "cnt =1\n",
    "# plt.subplots_adjust(0,0,1,1,0.01,0.01)\n",
    "plt.figure(figsize=(16,11))\n",
    "for i in range(250,260):    \n",
    "    plt.subplot(3,4,cnt)\n",
    "    plt.imshow(np.squeeze(rr[:,:,i]),'gray')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1572443-d6a1-4f0c-b3c0-9dd9cfe59db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "readdata, header = nrrd.read(val_label_files[1], index_order='C') #readdata (c h w)\n",
    "readdata = readdata[::-1] #reverse axial (-c h w)\n",
    "readdata = rearrange(readdata, 'c h w  -> h w c')\n",
    "readdata[readdata>0.5] = 1 #integrate label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3149776-5c0f-4d0d-8543-9c6750c464c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "readdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a275ece-c475-48f1-b8cc-30022867a0c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnt =1\n",
    "# plt.subplots_adjust(0,0,1,1,0.01,0.01)\n",
    "plt.figure(figsize=(16,11))\n",
    "for i in range(250,260):    \n",
    "    plt.subplot(3,4,cnt)\n",
    "    plt.imshow(readdata[:,:,i],'gray')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd32dee6-0abf-4006-bae5-c82c55ea8e2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rr = np.array(result[1])\n",
    "cnt =1\n",
    "# plt.subplots_adjust(0,0,1,1,0.01,0.01)\n",
    "plt.figure(figsize=(16,11))\n",
    "for i in range(250,260):    \n",
    "    plt.subplot(3,4,cnt)\n",
    "    plt.imshow(np.squeeze(rr[:,:,i]),'gray')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeb3ff9-5eaa-490b-88b8-fc18f4868757",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawimg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e4ab5a-b959-4a34-8c6e-a02e5a41dd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = predict(test_input_files[:1], stride=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d9f902-8841-46b9-80ad-73b049c50138",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(test_result).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85768d2-5cb4-4c15-81d9-2efae1558544",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "label_img, header = nrrd.read(test_label_files[n], index_order='C') #readdata (c h w)\n",
    "label_img = label_img[::-1] #reverse axial (-c h w)\n",
    "label_img = rearrange(label_img, 'c h w  -> h w c')\n",
    "label_img[label_img>0.5] = 1 #integrate label\n",
    "\n",
    "l = len(os.listdir(test_input_files[n]))\n",
    "rawimg = np.zeros((512,512,l))\n",
    "for i in range(l):\n",
    "    slice = pydicom.read_file(test_input_files[n]+'IMG'+str(i+1))\n",
    "    s = int(slice.RescaleSlope)\n",
    "    b = int(slice.RescaleIntercept)\n",
    "    image = s * slice.pixel_array + b\n",
    "    rawimg[:,:,i]=image\n",
    "rawimg = (rawimg-np.min(rawimg))/(np.max(rawimg)-np.min(rawimg))\n",
    "\n",
    "rr = np.array(test_result[0])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f622c5-06a4-44e7-8fe2-490f9b002f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.shape, label_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df79ee06-ee50-4fbd-add0-9932b74b761e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(0,rr.shape[2]):\n",
    "    print(i)\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(rawimg[:,:,i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(label_img[:,:,i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(np.squeeze(rr[:,:,i]), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    # plt.savefig('result'+str(i)+'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1e1254-debe-4d2a-bd57-eb382edb6792",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_result = np.squeeze(rr)\n",
    "np.save('./images/sampletest0.npy',sample_test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d535de2-248a-42a5-8778-bfa582768e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./images/samplelabel0.npy',label_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87013bdf-414d-4c46-8afb-2a2324dd4df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "label_img, header = nrrd.read(val_label_files[n], index_order='C') #readdata (c h w)\n",
    "label_img = label_img[::-1] #reverse axial (-c h w)\n",
    "label_img = rearrange(label_img, 'c h w  -> h w c')\n",
    "label_img[label_img>0.5] = 1 #integrate label\n",
    "\n",
    "l = len(os.listdir(val_input_files[n]))\n",
    "rawimg = np.zeros((512,512,l))\n",
    "for i in range(l):\n",
    "    slice = pydicom.read_file(val_input_files[n]+'IMG'+str(i+1))\n",
    "    s = int(slice.RescaleSlope)\n",
    "    b = int(slice.RescaleIntercept)\n",
    "    image = s * slice.pixel_array + b\n",
    "    rawimg[:,:,i]=image\n",
    "rawimg = (rawimg-np.min(rawimg))/(np.max(rawimg)-np.min(rawimg))\n",
    "\n",
    "rr = np.array(result[1])   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
